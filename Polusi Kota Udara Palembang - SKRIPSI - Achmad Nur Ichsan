import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from keras.models import Sequential, load_model
from keras.layers import Dense, LSTM, Dropout
from keras.callbacks import EarlyStopping
from keras.optimizers import Adam
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import streamlit as st
import os

# Define date range limits
MIN_DATE = pd.to_datetime("2018-01-01")
MAX_DATE = pd.to_datetime("2024-04-30")
MODEL_SAVE_PATH = "predebut_model_ispu_total.h5"

# Thresholds for ISPU levels
ISPU_THRESHOLDS = [50, 100, 200, 300, 500]
ISPU_LABELS = ['Good', 'Moderate', 'Unhealthy', 'Very Unhealthy', 'Hazardous']

# Function to validate file type
def validate_file(uploaded_file):
    if uploaded_file is None or not uploaded_file.name.endswith(".xlsx"):
        st.error("Format dataset tidak valid. Harap unggah file Excel (.xlsx).")
        return None
    return pd.read_excel(uploaded_file)

# Function to preprocess data for ISPU Total
def preprocess_ispu_total(data):
    column_name = 'ISPU_Total'
    if column_name not in data.columns:
        raise KeyError(f"Kolom '{column_name}' tidak ditemukan dalam dataset. Pastikan kolom tersebut ada.")

    data[column_name] = pd.to_numeric(data[column_name], errors='coerce')
    if data[column_name].isnull().all():
        raise ValueError("Dataset kosong setelah konversi data ISPU Total.")

    data[column_name].fillna(data[column_name].mean(), inplace=True)

    # Remove outliers using IQR method
    Q1 = data[column_name].quantile(0.25)
    Q3 = data[column_name].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    data = data[(data[column_name] >= lower_bound) & (data[column_name] <= upper_bound)]

    if data.empty:
        raise ValueError(f"Dataset kosong setelah preprocessing untuk kolom {column_name}. Periksa rentang data atau kriteria penyaringan.")

    return data[[column_name]]

# Function to calculate MAPE
def mean_absolute_percentage_error(y_true, y_pred):
    epsilon = 1e-10
    return np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100

# Function to train and evaluate model for ISPU Total
def train_model_for_ispu_total(data, look_back, epochs, batch_size, learning_rate):
    st.subheader("Training for ISPU Total")

    try:
        features = preprocess_ispu_total(data)
    except (KeyError, ValueError) as e:
        st.error(str(e))
        return

    # Normalize the data
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_features = scaler.fit_transform(features)

    # Split data into train and test sets
    train_size = int(len(scaled_features) * 0.7)
    train, test = scaled_features[:train_size], scaled_features[train_size:]

    # Create datasets for LSTM
    def create_dataset(dataset, look_back):
        X, Y = [], []
        for i in range(len(dataset) - look_back - 1):
            X.append(dataset[i:(i + look_back), :])
            Y.append(dataset[i + look_back, 0])
        return np.array(X), np.array(Y)

    trainX, trainY = create_dataset(train, look_back)
    testX, testY = create_dataset(test, look_back)

    trainX = np.reshape(trainX, (trainX.shape[0], look_back, trainX.shape[2]))
    testX = np.reshape(testX, (testX.shape[0], look_back, trainX.shape[2]))

    model_path = MODEL_SAVE_PATH

    if os.path.exists(model_path):
        model = load_model(model_path)
        st.success("Model pre-trained untuk ISPU Total berhasil dimuat.")
    else:
        model = Sequential()
        model.add(LSTM(150, return_sequences=True, activation='relu', input_shape=(look_back, 1)))
        model.add(Dropout(0.3))
        model.add(LSTM(100, return_sequences=False, activation='relu'))
        model.add(Dropout(0.3))
        model.add(Dense(1, activation='linear'))
        optimizer = Adam(learning_rate=learning_rate)
        model.compile(optimizer=optimizer, loss='mean_squared_error')

        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)
        model.fit(
            trainX, trainY,
            epochs=epochs,
            batch_size=batch_size,
            validation_data=(testX, testY),
            callbacks=[early_stopping],
            verbose=2
        )

        model.save(model_path)
        st.success(f"Model disimpan ke {model_path}")

    trainPredict = model.predict(trainX)
    testPredict = model.predict(testX)

    if np.isnan(trainPredict).any() or np.isnan(testPredict).any() or np.isnan(trainY).any() or np.isnan(testY).any():
        st.error("NaN ditemukan pada prediksi atau data aktual. Evaluasi dan plot dilewati.")
        return

    def invert_predictions(predictions, scaler):
        predictions = predictions.reshape(-1, 1)
        return scaler.inverse_transform(predictions)

    trainPredict = invert_predictions(trainPredict, scaler)
    testPredict = invert_predictions(testPredict, scaler)
    trainY = invert_predictions(trainY, scaler)
    testY = invert_predictions(testY, scaler)

    test_rmse = np.sqrt(mean_squared_error(testY, testPredict))
    test_mae = mean_absolute_error(testY, testPredict)
    test_mape = mean_absolute_percentage_error(testY, testPredict)

    st.write(f"RMSE: {test_rmse:.2f}, MAE: {test_mae:.2f}, MAPE: {test_mape:.2f}%")

    fig, ax = plt.subplots(figsize=(12, 6))
    ax.plot(testY, label='Actual ISPU Total (Test)', color='blue')
    ax.plot(testPredict, label='Predicted ISPU Total (Test)', color='orange')

    for i, threshold in enumerate(ISPU_THRESHOLDS):
        ax.axhline(y=threshold, color=['green', 'yellow', 'orange', 'red', 'purple'][i], linestyle='--', label=f'{ISPU_LABELS[i]} ({threshold})')

    ax.set_xlim(0, len(testY) + 3)
    ax.set_xlabel('Time Steps')
    ax.set_ylabel('ISPU Total Level')
    ax.set_title('ISPU Total Prediction with Levels')
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)

    return model

# Function to run LSTM for ISPU Total
def run_lstm(uploaded_file, start_date, end_date):
    data = validate_file(uploaded_file)
    if data is None:
        return

    if pd.to_datetime(start_date) < MIN_DATE or pd.to_datetime(end_date) > MAX_DATE:
        st.error(f"Tanggal harus berada dalam rentang {MIN_DATE.date()} hingga {MAX_DATE.date()}.")
        return
    if start_date > end_date:
        st.error("Tanggal mulai tidak boleh lebih besar dari tanggal akhir.")
        return

    data['Tanggal'] = pd.to_datetime(data['Tanggal'], format='%d %B %Y', errors='coerce')
    filtered_data = data[(data['Tanggal'] >= pd.to_datetime(start_date)) & (data['Tanggal'] <= pd.to_datetime(end_date))]
    if filtered_data.empty:
        st.error("Dataset kosong dalam rentang tanggal yang dipilih!")
        return

    train_model_for_ispu_total(filtered_data.copy(), look_back, epochs, batch_size, learning_rate)

st.title("LSTM Prediction for Air Quality")

st.sidebar.header("User Input Parameters")

def display_best_combinations():
    st.sidebar.subheader("Recommended Parameter Combinations")
    best_combinations = pd.DataFrame({
        'Epochs': [150, 300, 400],
        'Batch Size': [16, 128, 256],
        'Learning Rate': [0.0001, 0.001, 0.005],
        'Lookback': [60, 100, 300]
    })
    st.sidebar.table(best_combinations)

display_best_combinations()

epochs = st.sidebar.slider("Epochs", min_value=50, max_value=1000, value=200, step=50, format="%d")
batch_size = st.sidebar.slider("Batch Size", min_value=16, max_value=1024, value=128, step=16, format="%d")
learning_rate = st.sidebar.slider("Learning Rate", min_value=0.0001, max_value=0.1, value=0.001, step=0.0001, format="%f")
look_back = st.sidebar.slider("Lookback", min_value=10, max_value=300, value=100, step=10, format="%d")

st.sidebar.subheader("Date Range and File Input")
start_date = st.sidebar.date_input("Start Date", value=pd.to_datetime("2018-01-01"), min_value=MIN_DATE, max_value=MAX_DATE)
end_date = st.sidebar.date_input("End Date", value=pd.to_datetime("2024-04-30"), min_value=MIN_DATE, max_value=MAX_DATE)

uploaded_file = st.sidebar.file_uploader("Upload Excel File", type=["xlsx"])

if st.sidebar.button("Run LSTM Prediction"):
    run_lstm(uploaded_file, start_date, end_date)
